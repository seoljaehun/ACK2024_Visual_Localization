{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 947,
     "status": "ok",
     "timestamp": 1653286297493,
     "user": {
      "displayName": "양우민",
      "userId": "09434565168064209811"
     },
     "user_tz": -540
    },
    "id": "zU2hdo-iuDM_",
    "outputId": "859b86c5-d193-49ee-a854-dc8ec2a058ef"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup complete. Using torch 2.0.0 (NVIDIA GeForce RTX 3060)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(f\"Setup complete. Using torch {torch.__version__} ({torch.cuda.get_device_properties(0).name if torch.cuda.is_available() else 'CPU'})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1653286297494,
     "user": {
      "displayName": "양우민",
      "userId": "09434565168064209811"
     },
     "user_tz": -540
    },
    "id": "5Y38Lq6KuG75",
    "outputId": "7520b50d-4b64-4cee-966f-d7da245d704f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\kkm\\Downloads\\mmsegmentation\n"
     ]
    }
   ],
   "source": [
    "%cd mmsegmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 1488,
     "status": "ok",
     "timestamp": 1653286298980,
     "user": {
      "displayName": "양우민",
      "userId": "09434565168064209811"
     },
     "user_tz": -540
    },
    "id": "scnWNR9VuKnB"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\kkm\\anaconda3\\envs\\seg\\lib\\site-packages\\mmcv\\__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from mmseg.apis import inference_segmentor, init_segmentor, show_result_pyplot\n",
    "import mmcv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1653286298981,
     "user": {
      "displayName": "양우민",
      "userId": "09434565168064209811"
     },
     "user_tz": -540
    },
    "id": "nZ7kLaEfuMhh"
   },
   "outputs": [],
   "source": [
    "import os.path as osp\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1653286339358,
     "user": {
      "displayName": "양우민",
      "userId": "09434565168064209811"
     },
     "user_tz": -540
    },
    "id": "km0JLIuRumCX"
   },
   "outputs": [],
   "source": [
    "from mmseg.datasets.builder import DATASETS\n",
    "from mmseg.datasets.custom import CustomDataset\n",
    "\n",
    "classes = ('background', 'road')\n",
    "palette = [[0, 0, 0], [255, 127, 0]]\n",
    "\n",
    "@DATASETS.register_module()\n",
    "class Dataset(CustomDataset):\n",
    "  CLASSES = classes\n",
    "  PALETTE = palette\n",
    "  def __init__(self, split, **kwargs):\n",
    "    super().__init__(img_suffix='.png', seg_map_suffix='.png', \n",
    "                     split=split, **kwargs)\n",
    "    assert osp.exists(self.img_dir) and self.split is not None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 548,
     "status": "ok",
     "timestamp": 1653286339903,
     "user": {
      "displayName": "양우민",
      "userId": "09434565168064209811"
     },
     "user_tz": -540
    },
    "id": "Qx5ugOgwuxGW",
    "outputId": "ba8f3cb6-e354-4a58-f6ac-c3c4e8be1169"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "norm_cfg = dict(type='SyncBN', requires_grad=True)\n",
      "model = dict(\n",
      "    type='EncoderDecoder',\n",
      "    pretrained=None,\n",
      "    backbone=dict(\n",
      "        type='MixVisionTransformer',\n",
      "        in_channels=3,\n",
      "        embed_dims=64,\n",
      "        num_stages=4,\n",
      "        num_layers=[3, 6, 40, 3],\n",
      "        num_heads=[1, 2, 5, 8],\n",
      "        patch_sizes=[7, 3, 3, 3],\n",
      "        sr_ratios=[8, 4, 2, 1],\n",
      "        out_indices=(0, 1, 2, 3),\n",
      "        mlp_ratio=4,\n",
      "        qkv_bias=True,\n",
      "        drop_rate=0.0,\n",
      "        attn_drop_rate=0.0,\n",
      "        drop_path_rate=0.1,\n",
      "        init_cfg=dict(\n",
      "            type='Pretrained',\n",
      "            checkpoint=\n",
      "            'https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/segformer/mit_b5_20220624-658746d9.pth'\n",
      "        )),\n",
      "    decode_head=dict(\n",
      "        type='SegformerHead',\n",
      "        in_channels=[64, 128, 320, 512],\n",
      "        in_index=[0, 1, 2, 3],\n",
      "        channels=256,\n",
      "        dropout_ratio=0.1,\n",
      "        num_classes=19,\n",
      "        norm_cfg=dict(type='SyncBN', requires_grad=True),\n",
      "        align_corners=False,\n",
      "        loss_decode=dict(\n",
      "            type='CrossEntropyLoss', use_sigmoid=False, loss_weight=1.0)),\n",
      "    train_cfg=dict(),\n",
      "    test_cfg=dict(mode='slide', crop_size=(1024, 1024), stride=(768, 768)))\n",
      "dataset_type = 'CityscapesDataset'\n",
      "data_root = 'data/cityscapes/'\n",
      "img_norm_cfg = dict(\n",
      "    mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_rgb=True)\n",
      "crop_size = (1024, 1024)\n",
      "train_pipeline = [\n",
      "    dict(type='LoadImageFromFile'),\n",
      "    dict(type='LoadAnnotations'),\n",
      "    dict(type='Resize', img_scale=(2048, 1024), ratio_range=(0.5, 2.0)),\n",
      "    dict(type='RandomCrop', crop_size=(1024, 1024), cat_max_ratio=0.75),\n",
      "    dict(type='RandomFlip', prob=0.5),\n",
      "    dict(type='PhotoMetricDistortion'),\n",
      "    dict(\n",
      "        type='Normalize',\n",
      "        mean=[123.675, 116.28, 103.53],\n",
      "        std=[58.395, 57.12, 57.375],\n",
      "        to_rgb=True),\n",
      "    dict(type='Pad', size=(1024, 1024), pad_val=0, seg_pad_val=255),\n",
      "    dict(type='DefaultFormatBundle'),\n",
      "    dict(type='Collect', keys=['img', 'gt_semantic_seg'])\n",
      "]\n",
      "test_pipeline = [\n",
      "    dict(type='LoadImageFromFile'),\n",
      "    dict(\n",
      "        type='MultiScaleFlipAug',\n",
      "        img_scale=(2048, 1024),\n",
      "        flip=False,\n",
      "        transforms=[\n",
      "            dict(type='Resize', keep_ratio=True),\n",
      "            dict(type='RandomFlip'),\n",
      "            dict(\n",
      "                type='Normalize',\n",
      "                mean=[123.675, 116.28, 103.53],\n",
      "                std=[58.395, 57.12, 57.375],\n",
      "                to_rgb=True),\n",
      "            dict(type='ImageToTensor', keys=['img']),\n",
      "            dict(type='Collect', keys=['img'])\n",
      "        ])\n",
      "]\n",
      "data = dict(\n",
      "    samples_per_gpu=1,\n",
      "    workers_per_gpu=1,\n",
      "    train=dict(\n",
      "        type='CityscapesDataset',\n",
      "        data_root='data/cityscapes/',\n",
      "        img_dir='leftImg8bit/train',\n",
      "        ann_dir='gtFine/train',\n",
      "        pipeline=[\n",
      "            dict(type='LoadImageFromFile'),\n",
      "            dict(type='LoadAnnotations'),\n",
      "            dict(\n",
      "                type='Resize', img_scale=(2048, 1024), ratio_range=(0.5, 2.0)),\n",
      "            dict(\n",
      "                type='RandomCrop', crop_size=(1024, 1024), cat_max_ratio=0.75),\n",
      "            dict(type='RandomFlip', prob=0.5),\n",
      "            dict(type='PhotoMetricDistortion'),\n",
      "            dict(\n",
      "                type='Normalize',\n",
      "                mean=[123.675, 116.28, 103.53],\n",
      "                std=[58.395, 57.12, 57.375],\n",
      "                to_rgb=True),\n",
      "            dict(type='Pad', size=(1024, 1024), pad_val=0, seg_pad_val=255),\n",
      "            dict(type='DefaultFormatBundle'),\n",
      "            dict(type='Collect', keys=['img', 'gt_semantic_seg'])\n",
      "        ]),\n",
      "    val=dict(\n",
      "        type='CityscapesDataset',\n",
      "        data_root='data/cityscapes/',\n",
      "        img_dir='leftImg8bit/val',\n",
      "        ann_dir='gtFine/val',\n",
      "        pipeline=[\n",
      "            dict(type='LoadImageFromFile'),\n",
      "            dict(\n",
      "                type='MultiScaleFlipAug',\n",
      "                img_scale=(2048, 1024),\n",
      "                flip=False,\n",
      "                transforms=[\n",
      "                    dict(type='Resize', keep_ratio=True),\n",
      "                    dict(type='RandomFlip'),\n",
      "                    dict(\n",
      "                        type='Normalize',\n",
      "                        mean=[123.675, 116.28, 103.53],\n",
      "                        std=[58.395, 57.12, 57.375],\n",
      "                        to_rgb=True),\n",
      "                    dict(type='ImageToTensor', keys=['img']),\n",
      "                    dict(type='Collect', keys=['img'])\n",
      "                ])\n",
      "        ]),\n",
      "    test=dict(\n",
      "        type='CityscapesDataset',\n",
      "        data_root='data/cityscapes/',\n",
      "        img_dir='leftImg8bit/val',\n",
      "        ann_dir='gtFine/val',\n",
      "        pipeline=[\n",
      "            dict(type='LoadImageFromFile'),\n",
      "            dict(\n",
      "                type='MultiScaleFlipAug',\n",
      "                img_scale=(2048, 1024),\n",
      "                flip=False,\n",
      "                transforms=[\n",
      "                    dict(type='Resize', keep_ratio=True),\n",
      "                    dict(type='RandomFlip'),\n",
      "                    dict(\n",
      "                        type='Normalize',\n",
      "                        mean=[123.675, 116.28, 103.53],\n",
      "                        std=[58.395, 57.12, 57.375],\n",
      "                        to_rgb=True),\n",
      "                    dict(type='ImageToTensor', keys=['img']),\n",
      "                    dict(type='Collect', keys=['img'])\n",
      "                ])\n",
      "        ]))\n",
      "log_config = dict(\n",
      "    interval=50, hooks=[dict(type='TextLoggerHook', by_epoch=False)])\n",
      "dist_params = dict(backend='nccl')\n",
      "log_level = 'INFO'\n",
      "load_from = None\n",
      "resume_from = None\n",
      "workflow = [('train', 1)]\n",
      "cudnn_benchmark = True\n",
      "optimizer = dict(\n",
      "    type='AdamW',\n",
      "    lr=6e-05,\n",
      "    betas=(0.9, 0.999),\n",
      "    weight_decay=0.01,\n",
      "    paramwise_cfg=dict(\n",
      "        custom_keys=dict(\n",
      "            pos_block=dict(decay_mult=0.0),\n",
      "            norm=dict(decay_mult=0.0),\n",
      "            head=dict(lr_mult=10.0))))\n",
      "optimizer_config = dict()\n",
      "lr_config = dict(\n",
      "    policy='poly',\n",
      "    warmup='linear',\n",
      "    warmup_iters=1500,\n",
      "    warmup_ratio=1e-06,\n",
      "    power=1.0,\n",
      "    min_lr=0.0,\n",
      "    by_epoch=False)\n",
      "runner = dict(type='IterBasedRunner', max_iters=160000)\n",
      "checkpoint_config = dict(by_epoch=False, interval=16000)\n",
      "evaluation = dict(interval=16000, metric='mIoU', pre_eval=True)\n",
      "checkpoint = 'https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/segformer/mit_b5_20220624-658746d9.pth'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# config 파일을 설정하고, 다운로드 받은 pretrained 모델을 checkpoint로 설정. \n",
    "config_file = 'C:/Users/kkm/Downloads/mmsegmentation/configs/segformer/segformer_mit-b5_8x1_1024x1024_160k_cityscapes.py'\n",
    "checkpoint_file = 'C:/Users/kkm/Downloads/mmsegmentation/checkpoints/segformer_mit-b5_8x1_1024x1024_160k_cityscapes_20211206_072934-87a052ec.pth'\n",
    "\n",
    "from mmcv import Config\n",
    "\n",
    "cfg = Config.fromfile(config_file)\n",
    "print(cfg.pretty_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1653286339905,
     "user": {
      "displayName": "양우민",
      "userId": "09434565168064209811"
     },
     "user_tz": -540
    },
    "id": "rWBsQMhXvA4T"
   },
   "outputs": [],
   "source": [
    "model = dict(\n",
    "    type='EncoderDecoder',\n",
    "    pretrained='open-mmlab://resnet101_v1c',\n",
    "    backbone=dict(\n",
    "        type='ResNetV1c',\n",
    "        depth=101,\n",
    "        num_stages=4,\n",
    "        out_indices=(0, 1, 2, 3),\n",
    "        dilations=(1, 1, 1, 1),\n",
    "        strides=(1, 2, 2, 2),\n",
    "        norm_cfg=dict(type='BN', requires_grad=True),\n",
    "        norm_eval=False,\n",
    "        style='pytorch',\n",
    "        contract_dilation=True),\n",
    "    neck=dict(\n",
    "        type='FPN',\n",
    "        in_channels=[256, 512, 1024, 2048],\n",
    "        out_channels=256,\n",
    "        num_outs=4),\n",
    "    decode_head=dict(\n",
    "        type='FPNHead',\n",
    "        in_channels=[256, 256, 256, 256],\n",
    "        in_index=[0, 1, 2, 3],\n",
    "        feature_strides=[4, 8, 16, 32],\n",
    "        channels=128,\n",
    "        dropout_ratio=0.1,\n",
    "        num_classes=19,\n",
    "        norm_cfg=dict(type='BN', requires_grad=True),\n",
    "        align_corners=False,\n",
    "        loss_decode=dict(\n",
    "            type='CrossEntropyLoss', use_sigmoid=False, loss_weight=1.0)),\n",
    "    train_cfg=dict(),\n",
    "    test_cfg=dict(mode='whole'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1653286339906,
     "user": {
      "displayName": "양우민",
      "userId": "09434565168064209811"
     },
     "user_tz": -540
    },
    "id": "JVKVeenRvLWC"
   },
   "outputs": [],
   "source": [
    "img_norm_cfg = dict(\n",
    "    mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_rgb=True)\n",
    "crop_size = (512, 512)\n",
    "train_pipeline = [\n",
    "    dict(type='LoadImageFromFile'),\n",
    "    dict(type='LoadAnnotations'),\n",
    "    dict(type='Resize', img_scale=(1024, 1024), ratio_range=(0.5, 1.5)),\n",
    "    dict(type='RandomCrop', crop_size=(512, 512), cat_max_ratio=0.75),\n",
    "    dict(type='RandomFlip', prob=0.5),\n",
    "    dict(type='PhotoMetricDistortion'),\n",
    "    dict(\n",
    "        type='Normalize',\n",
    "        mean=[123.675, 116.28, 103.53],\n",
    "        std=[58.395, 57.12, 57.375],\n",
    "        to_rgb=True),\n",
    "    dict(type='Pad', size=(512, 512), pad_val=0, seg_pad_val=255),\n",
    "    dict(type='DefaultFormatBundle'),\n",
    "    dict(type='Collect', keys=['img', 'gt_semantic_seg'])\n",
    "]\n",
    "test_pipeline = [\n",
    "    dict(type='LoadImageFromFile'),\n",
    "    dict(\n",
    "        type='MultiScaleFlipAug',\n",
    "        img_scale=(1024, 1024),\n",
    "        flip=False,\n",
    "        transforms=[\n",
    "            dict(type='Resize', keep_ratio=True),\n",
    "            dict(type='RandomFlip'),\n",
    "            dict(\n",
    "                type='Normalize',\n",
    "                mean=[123.675, 116.28, 103.53],\n",
    "                std=[58.395, 57.12, 57.375],\n",
    "                to_rgb=True),\n",
    "            dict(type='ImageToTensor', keys=['img']),\n",
    "            dict(type='Collect', keys=['img'])\n",
    "        ])\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1653286339906,
     "user": {
      "displayName": "양우민",
      "userId": "09434565168064209811"
     },
     "user_tz": -540
    },
    "id": "RR2MIwc7vP7T"
   },
   "outputs": [],
   "source": [
    "dataset_type = 'CityscapesDataset'\n",
    "data_root = 'data/cityscapes/'\n",
    "\n",
    "data = dict(\n",
    "    samples_per_gpu=1,  #batch size\n",
    "    workers_per_gpu=0,\n",
    "    persistent_workers=False,  \n",
    "    train=dict(\n",
    "        type='CityscapesDataset',\n",
    "        data_root='data/cityscapes/',\n",
    "        img_dir='leftImg8bit/train',\n",
    "        ann_dir='gtFine/train',\n",
    "        pipeline=[\n",
    "            dict(type='LoadImageFromFile'),\n",
    "            dict(type='LoadAnnotations'),\n",
    "            dict(\n",
    "                type='Resize', img_scale=(1024, 1024), ratio_range=(0.5, 1.5)),\n",
    "            dict(type='RandomCrop', crop_size=(512, 512), cat_max_ratio=0.75),\n",
    "            dict(type='RandomFlip', prob=0.5),\n",
    "            dict(type='PhotoMetricDistortion'),\n",
    "            dict(\n",
    "                type='Normalize',\n",
    "                mean=[123.675, 116.28, 103.53],\n",
    "                std=[58.395, 57.12, 57.375],\n",
    "                to_rgb=True),\n",
    "            dict(type='Pad', size=(512, 512), pad_val=0, seg_pad_val=255),\n",
    "            dict(type='DefaultFormatBundle'),\n",
    "            dict(type='Collect', keys=['img', 'gt_semantic_seg'])\n",
    "        ]),\n",
    "    val=dict(\n",
    "        type='CityscapesDataset',\n",
    "        data_root='data/cityscapes/',\n",
    "        img_dir='leftImg8bit/val',\n",
    "        ann_dir='gtFine/val',\n",
    "        pipeline=[\n",
    "            dict(type='LoadImageFromFile'),\n",
    "            dict(\n",
    "                type='MultiScaleFlipAug',\n",
    "                img_scale=(1024, 1024),\n",
    "                flip=False,\n",
    "                transforms=[\n",
    "                    dict(type='Resize', keep_ratio=True),\n",
    "                    dict(type='RandomFlip'),\n",
    "                    dict(\n",
    "                        type='Normalize',\n",
    "                        mean=[123.675, 116.28, 103.53],\n",
    "                        std=[58.395, 57.12, 57.375],\n",
    "                        to_rgb=True),\n",
    "                    dict(type='ImageToTensor', keys=['img']),\n",
    "                    dict(type='Collect', keys=['img'])\n",
    "                ])\n",
    "        ]),\n",
    "    test=dict(\n",
    "        type='CityscapesDataset',\n",
    "        data_root='data/cityscapes/',\n",
    "        img_dir='leftImg8bit/val',\n",
    "        ann_dir='gtFine/val',\n",
    "        pipeline=[\n",
    "            dict(type='LoadImageFromFile'),\n",
    "            dict(\n",
    "                type='MultiScaleFlipAug',\n",
    "                img_scale=(1024, 1024),\n",
    "                flip=False,\n",
    "                transforms=[\n",
    "                    dict(type='Resize', keep_ratio=True),\n",
    "                    dict(type='RandomFlip'),\n",
    "                    dict(\n",
    "                        type='Normalize',\n",
    "                        mean=[123.675, 116.28, 103.53],\n",
    "                        std=[58.395, 57.12, 57.375],\n",
    "                        to_rgb=True),\n",
    "                    dict(type='ImageToTensor', keys=['img']),\n",
    "                    dict(type='Collect', keys=['img'])\n",
    "                ])\n",
    "        ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1653286339906,
     "user": {
      "displayName": "양우민",
      "userId": "09434565168064209811"
     },
     "user_tz": -540
    },
    "id": "caVFRT7QvWE8"
   },
   "outputs": [],
   "source": [
    "cfg.norm_cfg = dict(type='BN', requires_grad=True)\n",
    "#cfg.model.backbone.norm_cfg = cfg.norm_cfg\n",
    "cfg.model.decode_head.norm_cfg = cfg.norm_cfg\n",
    "\n",
    "cfg.model.decode_head.num_classes = 3\n",
    "\n",
    "cfg.model.decode_head.loss_decode = [dict(type='DiceLoss', loss_weight = 1.0, class_weight=[0.001, 0.7, 0.299]),\n",
    "                                     dict(type='FocalLoss', loss_weight = 1.0, class_weight=[0.001, 0.7, 0.299]),\n",
    "                                     dict(type='LovaszLoss', loss_weight = 1.0, reduction='none',class_weight=[0.001, 0.7, 0.299])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1653286339907,
     "user": {
      "displayName": "양우민",
      "userId": "09434565168064209811"
     },
     "user_tz": -540
    },
    "id": "X9IpatmxvYMt"
   },
   "outputs": [],
   "source": [
    "cfg.img_norm_cfg = dict(\n",
    "    mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_rgb=True)\n",
    "cfg.crop_size = (512, 512)\n",
    "cfg.train_pipeline = [\n",
    "    dict(type='LoadImageFromFile'),\n",
    "    dict(type='LoadAnnotations'),\n",
    "    dict(type='Resize', img_scale=(1024, 1024), ratio_range=(0.5, 1.5)),\n",
    "    dict(type='RandomCrop', crop_size=cfg.crop_size, cat_max_ratio=0.75),\n",
    "    dict(type='RandomFlip', flip_ratio=0.5),\n",
    "    dict(type='PhotoMetricDistortion'),\n",
    "    dict(type='Normalize', **cfg.img_norm_cfg),\n",
    "    dict(type='Pad', size=cfg.crop_size, pad_val=0, seg_pad_val=255),\n",
    "    dict(type='DefaultFormatBundle'),\n",
    "    dict(type='Collect', keys=['img', 'gt_semantic_seg']),\n",
    "]\n",
    "\n",
    "cfg.test_pipeline = [\n",
    "    dict(type='LoadImageFromFile'),\n",
    "    dict(\n",
    "        type='MultiScaleFlipAug',\n",
    "        img_scale=(1024, 1024),\n",
    "        # img_ratios=[0.5, 0.75, 1.0, 1.25, 1.5, 1.75],\n",
    "        flip=False,\n",
    "        transforms=[\n",
    "            dict(type='Resize', keep_ratio=True),\n",
    "            dict(type='RandomFlip'),\n",
    "            dict(type='Normalize', **cfg.img_norm_cfg),\n",
    "            dict(type='ImageToTensor', keys=['img']),\n",
    "            dict(type='Collect', keys=['img']),\n",
    "        ])\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1653286339907,
     "user": {
      "displayName": "양우민",
      "userId": "09434565168064209811"
     },
     "user_tz": -540
    },
    "id": "_4PNB6hGvds4"
   },
   "outputs": [],
   "source": [
    "cfg.data.samples_per_gpu=1\n",
    "cfg.data.workers_per_gpu=0\n",
    "cfg.data.persistent_workers=False\n",
    "cfg.dataset_type = 'Dataset'\n",
    "cfg.data_root = 'D:/'\n",
    "\n",
    "cfg.data.train.type = 'Dataset'\n",
    "cfg.data.train.data_root = 'D:/'\n",
    "cfg.data.train.img_dir = 'Data_set/road_dataset/img_dir/train'\n",
    "cfg.data.train.ann_dir = 'Data_set/road_dataset/contour_ann_dir/train'\n",
    "cfg.data.train.pipeline = cfg.train_pipeline\n",
    "cfg.data.train.split = 'D:/Data_set/road_dataset/mask_dir/train/up_train_road.txt'\n",
    "\n",
    "cfg.data.val.type = 'Dataset'\n",
    "cfg.data.val.data_root = 'D:/'\n",
    "cfg.data.val.img_dir = 'Data_set/road_dataset/img_dir/train'\n",
    "cfg.data.val.ann_dir = 'Data_set/road_dataset/contour_ann_dir/train'\n",
    "cfg.data.val.pipeline = cfg.test_pipeline\n",
    "cfg.data.val.split = 'D:/Data_set/road_dataset/mask_dir/train/up_val_road.txt'\n",
    "\n",
    "cfg.data.test.type = 'Dataset'\n",
    "cfg.data.test.data_root = 'D:/'\n",
    "cfg.data.test.img_dir = 'Data_set/road_dataset/img_dir/val'\n",
    "cfg.data.test.ann_dir = 'Data_set/road_dataset/contour_ann_dir/val'\n",
    "cfg.data.test.pipeline = cfg.test_pipeline\n",
    "cfg.data.test.split = 'D:/Data_set/road_dataset/mask_dir/val/up.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1653286339908,
     "user": {
      "displayName": "양우민",
      "userId": "09434565168064209811"
     },
     "user_tz": -540
    },
    "id": "l1Gc8ttSvw8e"
   },
   "outputs": [],
   "source": [
    "cfg.load_from = 'C:/Users/kkm/Downloads/mmsegmentation/checkpoints/segformer_mit-b5_8x1_1024x1024_160k_cityscapes_20211206_072934-87a052ec.pth'\n",
    "\n",
    "# Set up working dir to save files and logs.\n",
    "cfg.work_dir = 'D:/checkpoint/Segformer/road/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1073,
     "status": "ok",
     "timestamp": 1653286340972,
     "user": {
      "displayName": "양우민",
      "userId": "09434565168064209811"
     },
     "user_tz": -540
    },
    "id": "vvSIfRurv0sm",
    "outputId": "a9534a4a-a3a0-433f-fe60-35242f7c220c"
   },
   "outputs": [],
   "source": [
    "cfg.runner.max_iteTrs = 200\n",
    "cfg.log_config.interval = 100\n",
    "cfg.evaluation.interval = 1000  # 모델 학습시 평가를 몇 번째 iteration마다 할 것인지 지정\n",
    "cfg.checkpoint_config.interval = 1000  # 모델 학습시 학습한 모델을 몇 번째 iteration마다 저장할 것인지 지정\n",
    "\n",
    "cfg.runner = dict(type='IterBasedRunner', max_iters=20000)  # Iteration으로 동작, Epoch로 동작하게 변경할 수도 있음\n",
    "# cfg.runner = dict(type='EpochBasedRunner', max_epochs=4000)  # Epoch로 변경\n",
    "cfg.workflow = [('train', 1)]\n",
    "\n",
    "# Set seed to facitate reproducing the result\n",
    "cfg.seed = 0\n",
    "#set_random_seed(0, deterministic=False)\n",
    "cfg.gpu_ids = range(1)\n",
    "cfg.device='cuda'\n",
    "# Let's have a look at the final config used for training\n",
    "print(f'Config:\\n{cfg.pretty_text}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8739578,
     "status": "ok",
     "timestamp": 1653295080548,
     "user": {
      "displayName": "양우민",
      "userId": "09434565168064209811"
     },
     "user_tz": -540
    },
    "id": "8IlH2WxNwFFW",
    "outputId": "ffbd1244-86e0-4897-c879-1b6740b16365"
   },
   "outputs": [],
   "source": [
    "from mmseg.datasets import build_dataset\n",
    "from mmseg.models import build_segmentor\n",
    "from mmseg.apis import train_segmentor\n",
    "\n",
    "# Build the dataset\n",
    "datasets = [build_dataset(cfg.data.train)]\n",
    "\n",
    "# Build the detector\n",
    "model = build_segmentor(\n",
    "    cfg.model, train_cfg=cfg.get('train_cfg'), test_cfg=cfg.get('test_cfg'))\n",
    "\n",
    "# Add an attribute for visualization convenience\n",
    "model.CLASSES = datasets[0].CLASSES\n",
    "\n",
    "# Create work_dir\n",
    "mmcv.mkdir_or_exist(osp.abspath(cfg.work_dir))\n",
    "train_segmentor(model, datasets, cfg, distributed=False, validate=True,\n",
    "                meta=dict(CLASSES=classes, PALETTE=palette))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "Segformer_road_512x512_iter_20k_contour_loss_DFL_class_weight073.ipynb",
   "provenance": [
    {
     "file_id": "1-tUNSqxwGyamS6a3CkRHoXF5GMszfber",
     "timestamp": 1652320453219
    }
   ]
  },
  "kernelspec": {
   "display_name": "seg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
